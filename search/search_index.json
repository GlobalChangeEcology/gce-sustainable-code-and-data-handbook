{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GCE Sustainable Code &amp; Data Handbook","text":"<p>Practical guidance for sustainable research code and FAIR, reusable data in the GCE community.</p> <ul> <li>Read online: https://globalchangeecology.github.io/gce-sustainable-code-and-data-handbook/</li> <li>Source on GitHub: https://github.com/GlobalChangeEcology/gce-sustainable-code-and-data-handbook</li> </ul>"},{"location":"#start-here","title":"Start here","text":"<ul> <li>Policy &amp; Principles \u2192 goals, scope, roles</li> <li>Project Setup \u2192 folders, naming, onboarding checklist</li> <li>Software Practices \u2192 version control, tests, docs, environments</li> <li>Data Lifecycle \u2192 collection \u2192 cleaning \u2192 analysis \u2192 publication</li> <li>Checklists &amp; Templates \u2192 ready-to-use templates</li> </ul>"},{"location":"#local-preview","title":"Local preview","text":"<pre><code>python3 -m pip install --upgrade mkdocs mkdocs-material\nmkdocs serve\n</code></pre>"},{"location":"DECISION_GUIDE/","title":"Decision Guide","text":"<p>Use this flow to pick tools and repositories.</p> <pre><code>flowchart TD\n  A[Start] --&gt; B{Primary need?}\n  B --&gt;|Analyze data| C{Preferred language?}\n  C --&gt;|Python| C1[Python env (Conda/Poetry) + Pandas]\n  C --&gt;|R| C2[R env (renv) + tidyverse]\n  B --&gt;|Automate pipeline| D{Size/cluster?}\n  D --&gt;|Small/Local| D1[Snakemake]\n  D --&gt;|Large/HPC| D2[Nextflow]\n  B --&gt;|Publish dataset| E{Discipline?}\n  E --&gt;|Environmental/Earth| E1[PANGAEA]\n  E --&gt;|Biodiversity| E2[GBIF]\n  E --&gt;|General| E3[Zenodo]\n  B --&gt;|Code &amp; results website| F[MkDocs + GitHub Pages]\n  C1 --&gt; G[Add validation: pandera]\n  C2 --&gt; H[Add validation: pointblank]\n  D1 --&gt; I[Capture envs per rule]\n  D2 --&gt; J[Containers + profiles]\n  E1 --&gt; K[Prepare README + dictionary]\n  E2 --&gt; K\n  E3 --&gt; K</code></pre>"},{"location":"DIAGRAMS/","title":"Diagrams","text":""},{"location":"DIAGRAMS/#project-folder-structure","title":"Project Folder Structure","text":"<pre><code>flowchart TD\n    A[Project Root]\n    A --&gt; B[00_ADMIN]\n    A --&gt; C[01_RAWDATA]\n    C --&gt; C1[Field]\n    C --&gt; C2[Lab]\n    C --&gt; C3[Geo]\n    A --&gt; D[02_METADATA]\n    A --&gt; E[03_CLEAN]\n    A --&gt; F[04_ANALYSIS]\n    A --&gt; G[05_RESULTS]\n    A --&gt; H[06_PUBLICATION]\n    A --&gt; I[07_ARCHIVE]</code></pre>"},{"location":"DIAGRAMS/#data-lifecycle","title":"Data Lifecycle","text":"<pre><code>flowchart LR\n    P[Plan] --&gt; I[Collect/Ingest]\n    I --&gt; O[Organize]\n    O --&gt; T[Clean/Transform]\n    T --&gt; A[Analyze]\n    A --&gt; R[Review]\n    R --&gt; U[Publish]\n    U --&gt; V[Archive]\n    V --&gt;|feedback| P</code></pre>"},{"location":"FAQ/","title":"FAQ \u2014 Common Questions","text":""},{"location":"FAQ/#i-only-have-excel-is-that-okay","title":"I only have Excel. Is that okay?","text":"<p>Yes. Save to CSV for analysis and keep your original Excel files as raw. Document steps you take in Excel in the README.</p>"},{"location":"FAQ/#do-i-have-to-learn-git","title":"Do I have to learn Git?","text":"<p>It\u2019s strongly recommended. Start with: commit, branch, pull request. It pays off quickly when collaborating.</p>"},{"location":"FAQ/#what-if-my-data-are-sensitive","title":"What if my data are sensitive?","text":"<p>See Sensitive Data. You may need anonymization and restricted access; talk to the Data Steward early.</p>"},{"location":"FAQ/#which-repository-should-i-publish-to","title":"Which repository should I publish to?","text":"<p>Use Zenodo for general data/code. PANGAEA for environmental datasets, GBIF for biodiversity occurrences. Ask if unsure.</p>"},{"location":"FAQ/#how-do-i-cite-my-dataset","title":"How do I cite my dataset?","text":"<p>Mint a DOI (e.g., via Zenodo). Include the citation in your README and publications.</p>"},{"location":"GLOSSARY/","title":"Glossary (Plain Language)","text":"<ul> <li>Data dictionary: A table that explains every column in your dataset.</li> <li>FAIR: Principles to make data easy to find, access, combine, and reuse.</li> <li>Git: A system that tracks changes in your files so you can go back in time.</li> <li>Git LFS: Extension for storing large files (like images or big data) in Git.</li> <li>Metadata: Information that describes your data (who, what, when, where, how).</li> <li>README: A short, human-readable guide that explains what a folder or dataset is.</li> <li>Schema: A set of rules for what your data should look like (types, ranges).</li> <li>Versioning: Keeping track of different versions as you improve files.</li> </ul>"},{"location":"IMPLEMENTATION_GUIDE/","title":"Implementation Guide \u2014 Data Management at GCE","text":"<p>This guide explains how to adopt the manual across the department.</p>"},{"location":"IMPLEMENTATION_GUIDE/#objectives","title":"Objectives","text":"<ul> <li>Ensure consistent, high-quality data management aligned with FAIR and DFG.</li> <li>Reduce risk of data loss and improve reproducibility and reuse.</li> </ul>"},{"location":"IMPLEMENTATION_GUIDE/#roles-responsibilities","title":"Roles &amp; Responsibilities","text":"<ul> <li>Project Lead: accountable for compliance and resources.</li> <li>Data Steward: owner of policy, training, reviews, and support.</li> <li>IT/Infrastructure: storage, backup, and access management.</li> <li>All Staff: follow standards, complete checklists, and maintain metadata.</li> </ul>"},{"location":"IMPLEMENTATION_GUIDE/#rollout-phases","title":"Rollout Phases","text":"<p>1) Preparation (Weeks 1\u20132) - Approve policy (01) and baseline requirements. - Create GitLab group templates and Nextcloud/NAS group folders. - Publish manual and templates to department space.</p> <p>2) Pilot (Weeks 3\u20138) - Select 2\u20133 active projects; migrate to standard structure. - Run checklists and capture feedback. - Set up CI checks (schema validation) on one project.</p> <p>3) Department-wide Launch (Month 3) - Require standard structure for all new projects. - Training: 60-min intro + 90-min hands-on (folder structure, README, dictionary, Git basics). - Office hours weekly for support.</p> <p>4) Consolidation (Months 4\u20136) - Migrate legacy projects opportunistically (when active). - Track metrics and address gaps; refine templates.</p>"},{"location":"IMPLEMENTATION_GUIDE/#minimal-technical-setup","title":"Minimal Technical Setup","text":"<ul> <li>Storage: NAS/HPC with nightly backups; Nextcloud for sharing.</li> <li>Version Control: GitLab with protected <code>main</code>, LFS enabled, group-level templates.</li> <li>Validation: frictionless/pandera checks optional in CI.</li> <li>Publishing: Zenodo or domain repository; DOI on releases.</li> </ul>"},{"location":"IMPLEMENTATION_GUIDE/#checkpoints-metrics","title":"Checkpoints &amp; Metrics","text":"<ul> <li>% projects with <code>README.md</code> + <code>data_dictionary.csv</code>.</li> <li>% releases with DOIs and complete submission package.</li> <li>Backup verification success rate (monthly).</li> <li>Training completion for new members.</li> </ul>"},{"location":"IMPLEMENTATION_GUIDE/#governance-change-control","title":"Governance &amp; Change Control","text":"<ul> <li>Manual lives in version control; updates via Merge Requests.</li> <li>Review cadence: every 6 months; emergency updates as needed.</li> <li>Data Steward publishes a changelog and announces updates.</li> </ul>"},{"location":"IMPLEMENTATION_GUIDE/#quick-start-for-new-projects","title":"Quick Start for New Projects","text":"<ol> <li>Create folder using standard structure.</li> <li>Fill <code>PROJECT_README.md</code> and dataset <code>README.md</code> + <code>data_dictionary.csv</code>.</li> <li>Initialize Git repo; enable LFS; push to GitLab.</li> <li>Capture environment (Conda/renv) and add pipeline (optional).</li> <li>At milestones, create a release and archive in <code>07_ARCHIVE/</code>.</li> </ol>"},{"location":"IMPLEMENTATION_GUIDE/#tooling-options-choose-your-own-stack","title":"Tooling Options (Choose-Your-Own-Stack)","text":"<ul> <li>Python + Conda + Snakemake + frictionless + pandera</li> <li>R + renv + targets/drake + pointblank</li> <li>Mixed: Notebooks (Jupyter/Quarto), QGIS, GDAL for geospatial</li> </ul>"},{"location":"IMPLEMENTATION_GUIDE/#support","title":"Support","text":"<ul> <li>Contact: Data Steward (email here)</li> <li>Training calendar and office hours: link here</li> <li>FAQs: add/link as the program matures</li> </ul>"},{"location":"QUICK_START_PYTHON/","title":"Quick Start \u2014 Python","text":"<p>Follow these steps to analyze a small CSV reproducibly.</p>"},{"location":"QUICK_START_PYTHON/#1-environment","title":"1) Environment","text":"<pre><code>conda create -n gce-quickstart python=3.11 -y\nconda activate gce-quickstart\npip install pandas frictionless pandera\n</code></pre>"},{"location":"QUICK_START_PYTHON/#2-data-dictionary","title":"2) Data dictionary","text":"<p>Create <code>data_dictionary.csv</code> like: <pre><code>name,type,unit,description,allowed_values,missing_values\nid,integer,,Unique identifier,,\nvalue,number,unitless,Example measurement,,\n</code></pre></p>"},{"location":"QUICK_START_PYTHON/#3-validate-data-optional-but-recommended","title":"3) Validate data (optional but recommended)","text":"<pre><code># validate.py\nimport pandas as pd\nimport pandera as pa\n\nschema = pa.DataFrameSchema({\n    \"id\": pa.Column(int),\n    \"value\": pa.Column(float)\n})\n\ndf = pd.read_csv(\"03_CLEAN/example.csv\")\nschema.validate(df)\nprint(\"Validation passed\")\n</code></pre>"},{"location":"QUICK_START_PYTHON/#4-reproducible-script","title":"4) Reproducible script","text":"<pre><code># summarize.py\nimport pandas as pd\n\ndf = pd.read_csv(\"03_CLEAN/example.csv\")\nsummary = df.describe()\nsummary.to_csv(\"05_RESULTS/summary.csv\")\nprint(\"Wrote 05_RESULTS/summary.csv\")\n</code></pre>"},{"location":"QUICK_START_PYTHON/#5-run","title":"5) Run","text":"<pre><code>python validate.py\npython summarize.py\n</code></pre>"},{"location":"QUICK_START_PYTHON/#6-next","title":"6) Next","text":"<ul> <li>Save your environment: <code>conda env export &gt; environment.yml</code></li> <li>Commit all changes; push to your repo</li> <li>Consider a Snakemake pipeline when steps grow</li> </ul>"},{"location":"QUICK_START_R/","title":"Quick Start \u2014 R","text":""},{"location":"QUICK_START_R/#1-environment","title":"1) Environment","text":"<p>Install packages and initialize renv: <pre><code>install.packages(c(\"renv\",\"readr\",\"dplyr\",\"pointblank\"))\nrenv::init()\n</code></pre></p>"},{"location":"QUICK_START_R/#2-data-dictionary","title":"2) Data dictionary","text":"<p>Create <code>data_dictionary.csv</code>: <pre><code>name,type,unit,description,allowed_values,missing_values\nid,integer,,Unique identifier,,\nvalue,number,unitless,Example measurement,,\n</code></pre></p>"},{"location":"QUICK_START_R/#3-validate-data-optional","title":"3) Validate data (optional)","text":"<pre><code># validate.R\nlibrary(pointblank)\n\nagent &lt;- create_agent(readr::read_csv(\"03_CLEAN/example.csv\")) %&gt;%\n  col_is_integer(\"id\") %&gt;%\n  col_exists(\"value\")\n\ninvisible(interrogate(agent))\n</code></pre>"},{"location":"QUICK_START_R/#4-reproducible-script","title":"4) Reproducible script","text":"<pre><code># summarize.R\nlibrary(readr); library(dplyr)\nread_csv(\"03_CLEAN/example.csv\") %&gt;%\n  summarize(mean_value = mean(value, na.rm = TRUE), n = n()) %&gt;%\n  readr::write_csv(\"05_RESULTS/summary.csv\")\n</code></pre>"},{"location":"QUICK_START_R/#5-run","title":"5) Run","text":"<pre><code>Rscript validate.R\nRscript summarize.R\n</code></pre>"},{"location":"QUICK_START_R/#6-next","title":"6) Next","text":"<ul> <li>Snapshot environment: <code>renv::snapshot()</code></li> <li>Commit and push</li> <li>Consider <code>targets</code> for pipelines as projects grow</li> </ul>"},{"location":"START_HERE/","title":"Start Here","text":"<p>Welcome! This handbook helps you set up sustainable code and FAIR, reusable data. If you\u2019ve never done this before, follow the path below.</p>"},{"location":"START_HERE/#your-first-project-in-30-minutes","title":"Your first project in 30 minutes","text":"<ol> <li>Create the project folders (copy from Project Setup).</li> <li>Add a dataset <code>README.md</code> and <code>data_dictionary.csv</code> from templates.</li> <li>Put raw data in <code>01_RAWDATA/</code> (don\u2019t edit it). Work in <code>03_CLEAN/</code>.</li> <li>Initialize Git. Commit often. Enable LFS for big files.</li> <li>Capture your environment (Conda/renv). Save it in the repo.</li> <li>Run the QA checklist before sharing or publishing.</li> </ol>"},{"location":"START_HERE/#what-to-read-next","title":"What to read next","text":"<ul> <li>Project Setup: how to structure and name things</li> <li>Software Practices: write code that others can understand and run</li> <li>Data Lifecycle: how to go from collection to publication</li> <li>Checklists &amp; Templates: copy-paste to get started fast</li> </ul>"},{"location":"START_HERE/#if-you-get-stuck","title":"If you get stuck","text":"<ul> <li>Use the Glossary for unfamiliar terms</li> <li>See the FAQ for common pitfalls</li> <li>Ask the Data Steward for help (contact in Implementation Guide)</li> </ul>"},{"location":"examples/minimal-project/","title":"Example \u2014 Minimal Project","text":"<p>This small example shows the folder layout and a tiny workflow.</p>"},{"location":"examples/minimal-project/#structure","title":"Structure","text":"<pre><code>Project_Acronym_Year/\n\u251c\u2500\u2500 01_RAWDATA/\n\u251c\u2500\u2500 02_METADATA/\n\u251c\u2500\u2500 03_CLEAN/\n\u251c\u2500\u2500 04_ANALYSIS/\n\u251c\u2500\u2500 05_RESULTS/\n\u2514\u2500\u2500 06_PUBLICATION/\n</code></pre>"},{"location":"examples/minimal-project/#steps","title":"Steps","text":"<ol> <li>Place a small CSV in <code>01_RAWDATA/</code>.</li> <li>Create a cleaned version in <code>03_CLEAN/</code> (fix headers, types, etc.).</li> <li>Run a simple summary script (Python or R) from the quick starts.</li> <li>Save results to <code>05_RESULTS/</code>.</li> </ol>"},{"location":"examples/minimal-project/#learn","title":"Learn","text":"<ul> <li>How to separate raw and clean data</li> <li>Where to put scripts and results</li> <li>How to document with README and a data dictionary</li> </ul>"},{"location":"manual/01_POLICY_AND_PRINCIPLES/","title":"01 \u2014 Policy &amp; Principles","text":"<p>Purpose: Define why we manage data, who is responsible, and the standards we follow.</p>"},{"location":"manual/01_POLICY_AND_PRINCIPLES/#scope","title":"Scope","text":"<ul> <li>Applies to all research projects under the Chair of Global Change Ecology (GCE), University of W\u00fcrzburg.</li> <li>Covers data, code, documentation, and derived outputs.</li> </ul>"},{"location":"manual/01_POLICY_AND_PRINCIPLES/#roles","title":"Roles","text":"<ul> <li>Project Lead: accountable for data quality and compliance.</li> <li>Data Steward: owner of this policy, support, training, audits.</li> <li>All Staff: follow this manual, maintain metadata, use approved tools.</li> </ul>"},{"location":"manual/01_POLICY_AND_PRINCIPLES/#principles","title":"Principles","text":"<ul> <li>FAIR: Findable, Accessible, Interoperable, Reusable.</li> <li>Good Scientific Practice (DFG): integrity, reproducibility, retention.</li> <li>Open by default: publish data/code unless legal/ethical constraints apply.</li> <li>Privacy &amp; Ethics: comply with GDPR and ethics approvals for personal/sensitive data.</li> </ul>"},{"location":"manual/01_POLICY_AND_PRINCIPLES/#minimum-requirements-baseline","title":"Minimum Requirements (Baseline)","text":"<ul> <li>Standard project structure and naming conventions are mandatory.</li> <li>Raw data are immutable in <code>01_RAWDATA/</code>.</li> <li>Every dataset has a <code>README.md</code> and data dictionary.</li> <li>Git/GitLab for code with protected <code>main</code> and releases.</li> <li>Backups on university-managed infrastructure.</li> </ul>"},{"location":"manual/01_POLICY_AND_PRINCIPLES/#review-enforcement","title":"Review &amp; Enforcement","text":"<ul> <li>Policy owner: Data Steward.</li> <li>Review cadence: every 6 months via Merge Request.</li> <li>Non-compliance escalated to Project Lead; remediation plan within 2 weeks.</li> </ul>"},{"location":"manual/02_PROJECT_SETUP/","title":"02 \u2014 Project Setup","text":""},{"location":"manual/02_PROJECT_SETUP/#standard-folder-structure","title":"Standard Folder Structure","text":"<p>Use this structure for every project:</p> <pre><code>Project_Acronym_Year/\n\u251c\u2500\u2500 00_ADMIN/\n\u251c\u2500\u2500 01_RAWDATA/\n\u2502   \u251c\u2500\u2500 Field/\n\u2502   \u251c\u2500\u2500 Lab/\n\u2502   \u2514\u2500\u2500 Geo/\n\u251c\u2500\u2500 02_METADATA/\n\u251c\u2500\u2500 03_CLEAN/\n\u251c\u2500\u2500 04_ANALYSIS/\n\u251c\u2500\u2500 05_RESULTS/\n\u251c\u2500\u2500 06_PUBLICATION/\n\u2514\u2500\u2500 07_ARCHIVE/\n</code></pre>"},{"location":"manual/02_PROJECT_SETUP/#naming-conventions","title":"Naming Conventions","text":"<p>Format: <code>Project_Acronym_Date_Version_Description</code> - Date: <code>YYYY-MM-DD</code> (ISO-8601) - Version: <code>v01</code>, <code>v02</code>, ... (semantic versions for code) - Use lowercase, <code>_</code> or <code>-</code>; no spaces or special characters</p>"},{"location":"manual/02_PROJECT_SETUP/#onboarding-checklist-project-start","title":"Onboarding Checklist (Project Start)","text":"<ul> <li>[ ] Create project folder from template</li> <li>[ ] Assign Project Lead and Data Steward contact</li> <li>[ ] Initialize GitLab repository (enable LFS)</li> <li>[ ] Create <code>02_METADATA/README.md</code> and data dictionary stub</li> <li>[ ] Set up storage locations (NAS/Nextcloud paths)</li> <li>[ ] Register DMP in RDMO (if required by funder)</li> </ul>"},{"location":"manual/03_METADATA_AND_DOCUMENTATION/","title":"03 \u2014 Metadata &amp; Documentation","text":""},{"location":"manual/03_METADATA_AND_DOCUMENTATION/#dataset-readme","title":"Dataset README","text":"<p>Each dataset directory must contain a <code>README.md</code> covering: - Title, description, authors, contact - Date, version, license - Methods and instruments/software - Data structure (variables, units, descriptions) - QA/validation steps - Provenance and limitations</p> <p>See template in <code>manual/templates/README_dataset.md</code>.</p>"},{"location":"manual/03_METADATA_AND_DOCUMENTATION/#data-dictionary-codebook","title":"Data Dictionary (Codebook)","text":"<ul> <li>Provide a machine- and human-readable schema of variables.</li> <li>Prefer CSV/TSV with columns: <code>name</code>, <code>type</code>, <code>unit</code>, <code>description</code>, <code>allowed_values</code>, <code>missing_values</code>.</li> <li>Link the dictionary in the dataset <code>README.md</code>.</li> </ul>"},{"location":"manual/03_METADATA_AND_DOCUMENTATION/#project-level-documentation","title":"Project-level Documentation","text":"<ul> <li><code>02_METADATA/PROJECT_README.md</code>: scope, team, dependencies, milestones</li> <li><code>CITATION.cff</code>: how to cite the project</li> <li><code>LICENSE</code>: default CC-BY 4.0 for data unless restricted</li> </ul>"},{"location":"manual/03_METADATA_AND_DOCUMENTATION/#metadata-standards","title":"Metadata Standards","text":"<ul> <li>General: Dublin Core elements for citation-level metadata</li> <li>Tabular data: Frictionless Data (Table Schema / Data Package)</li> <li>Biodiversity: Darwin Core (DwC)</li> <li>Geospatial: ISO 19115/19139; include CRS, bounding box, and resolution</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/","title":"04 \u2014 Data Lifecycle","text":"<p>This section defines required practices across the data lifecycle.</p>"},{"location":"manual/04_DATA_LIFECYCLE/#1-plan","title":"1) Plan","text":"<ul> <li>Define objectives, data types, sensitivity, and responsibilities.</li> <li>Register or update a DMP (e.g., in RDMO) if required.</li> <li>Decide storage locations and access groups.</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/#2-collect-ingest","title":"2) Collect / Ingest","text":"<ul> <li>Store new raw data in <code>01_RAWDATA/</code> (immutable).</li> <li>Capture acquisition context in <code>02_METADATA/README.md</code> (who/what/when/where/how).</li> <li>Use consistent file naming and timestamps (UTC for instruments).</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/#3-organize","title":"3) Organize","text":"<ul> <li>Maintain the standard folder structure; do not mix raw and derived data.</li> <li>Add or update <code>data_dictionary.csv</code> for new tabular datasets.</li> <li>Log external data sources with citation and license.</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/#4-clean-transform","title":"4) Clean / Transform","text":"<ul> <li>Work on copies in <code>03_CLEAN/</code> only; never edit <code>01_RAWDATA/</code>.</li> <li>Use scripted transformations (R/Python); save scripts in <code>04_ANALYSIS/</code>.</li> <li>Record provenance in <code>README.md</code> (inputs \u2192 steps \u2192 outputs).</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/#5-analyze","title":"5) Analyze","text":"<ul> <li>Keep analysis code under Git with branches and MRs.</li> <li>Capture environments (Conda/renv) or container recipes.</li> <li>Prefer pipeline tools (Snakemake/Nextflow) for reproducibility.</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/#6-review","title":"6) Review","text":"<ul> <li>Peer review analysis and data changes using Merge Requests.</li> <li>Run automated checks (schema validation, tests, linting) in CI.</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/#7-publish","title":"7) Publish","text":"<ul> <li>Prepare a release package: cleaned data, README, dictionary, code snapshot, environment.</li> <li>Choose repository (Zenodo/PANGAEA/GBIF/Dryad) and license.</li> <li>Obtain DOI and draft citation text.</li> </ul>"},{"location":"manual/04_DATA_LIFECYCLE/#8-archive-preserve","title":"8) Archive &amp; Preserve","text":"<ul> <li>Copy finalized data + README to <code>07_ARCHIVE/</code>.</li> <li>Ensure long-term storage on university-managed infrastructure.</li> <li>Document retention periods; verify restore via periodic test restores.</li> </ul>"},{"location":"manual/05_FILE_AND_VERSION_CONTROL/","title":"05 \u2014 File &amp; Version Control","text":""},{"location":"manual/05_FILE_AND_VERSION_CONTROL/#gitgitlab-workflow-code-text","title":"Git/GitLab Workflow (Code &amp; Text)","text":"<ul> <li>Default branches: <code>main</code> (protected), <code>develop</code> (optional), feature branches.</li> <li>Use Merge Requests with mandatory review before merging to <code>main</code>.</li> <li>Tag releases: <code>vMAJOR.MINOR.PATCH</code> with changelog.</li> <li>Use Git LFS for large binaries (e.g., <code>.tif</code>, <code>.nc</code>, <code>.h5</code>, <code>.zip</code>).</li> </ul>"},{"location":"manual/05_FILE_AND_VERSION_CONTROL/#data-versioning-conventions","title":"Data Versioning Conventions","text":"<ul> <li>Raw data are immutable; corrections documented as new files with versioned names.</li> <li>Cleaned datasets include a version in the filename and README (e.g., <code>v01</code>).</li> <li>Maintain a CHANGELOG in <code>02_METADATA/</code> for major dataset updates.</li> </ul>"},{"location":"manual/05_FILE_AND_VERSION_CONTROL/#reproducible-environments","title":"Reproducible Environments","text":"<ul> <li>Python: Conda/Poetry with <code>environment.yml</code> or <code>pyproject.toml</code>.</li> <li>R: <code>renv.lock</code> committed; optionally rocker/Apptainer images.</li> <li>Pin versions in environment files; document OS/CPU/GPU constraints.</li> </ul>"},{"location":"manual/05_FILE_AND_VERSION_CONTROL/#releases-and-dois","title":"Releases and DOIs","text":"<ul> <li>Create a GitLab Release for major milestones.</li> <li>Connect GitLab to Zenodo for automatic DOI minting on release (optional).</li> <li>Include <code>CITATION.cff</code> and a release checklist in the repository.</li> </ul>"},{"location":"manual/06_DATA_QUALITY/","title":"06 \u2014 Data Quality","text":""},{"location":"manual/06_DATA_QUALITY/#quality-objectives","title":"Quality Objectives","text":"<ul> <li>Accuracy, completeness, consistency, timeliness, and traceability.</li> </ul>"},{"location":"manual/06_DATA_QUALITY/#validation-checks","title":"Validation &amp; Checks","text":"<ul> <li>Define a schema (types, ranges, allowed values) per dataset.</li> <li>Automate checks using Frictionless (Table Schema) or pandera (Python) / pointblank (R).</li> <li>Add unit tests for critical transformations.</li> </ul>"},{"location":"manual/06_DATA_QUALITY/#qa-process","title":"QA Process","text":"<ul> <li>Ingestion QA: verify file integrity, row/column counts, missing values.</li> <li>Cleaning QA: before/after summaries, outlier review, sampling spot checks.</li> <li>Peer review QA via MR; track issues and resolutions.</li> </ul>"},{"location":"manual/06_DATA_QUALITY/#audit-trail","title":"Audit Trail","text":"<ul> <li>Log changes in README/CHANGELOG with dates and authors.</li> <li>Keep scripts in version control; avoid manual spreadsheet edits.</li> </ul>"},{"location":"manual/06_DATA_QUALITY/#acceptance-criteria","title":"Acceptance Criteria","text":"<ul> <li>Dataset must pass automated schema checks.</li> <li>README + data dictionary complete; license and citation provided.</li> <li>Sensitive data reviewed against policy before publication.</li> </ul>"},{"location":"manual/07_SENSITIVE_DATA/","title":"07 \u2014 Sensitive Data","text":""},{"location":"manual/07_SENSITIVE_DATA/#definitions-scope","title":"Definitions &amp; Scope","text":"<ul> <li>Personal data (GDPR), confidential agreements, sensitive locations/species.</li> <li>Classify datasets: Public / Internal / Restricted.</li> </ul>"},{"location":"manual/07_SENSITIVE_DATA/#legal-ethical-basis","title":"Legal &amp; Ethical Basis","text":"<ul> <li>Ensure lawful basis (consent, contract, public interest) and ethics approvals.</li> <li>Data minimisation: collect only what is necessary.</li> </ul>"},{"location":"manual/07_SENSITIVE_DATA/#protection-measures","title":"Protection Measures","text":"<ul> <li>Access control: group-based permissions on NAS/Nextcloud/GitLab.</li> <li>Pseudonymisation/anonymisation where feasible; store keys separately.</li> <li>Encryption at rest (infrastructure) and in transit (TLS); avoid email attachments.</li> </ul>"},{"location":"manual/07_SENSITIVE_DATA/#retention-deletion","title":"Retention &amp; Deletion","text":"<ul> <li>Define retention periods; document in project metadata.</li> <li>Secure deletion on request/expiry; record in a deletion log.</li> </ul>"},{"location":"manual/07_SENSITIVE_DATA/#sharing-publication","title":"Sharing &amp; Publication","text":"<ul> <li>Remove direct identifiers; evaluate re-identification risk.</li> <li>Use controlled-access repositories if needed; specify data use agreements.</li> </ul>"},{"location":"manual/08_TOOLS_AND_PLATFORMS/","title":"08 \u2014 Tools &amp; Platforms","text":""},{"location":"manual/08_TOOLS_AND_PLATFORMS/#storage-backup","title":"Storage &amp; Backup","text":"<ul> <li>Primary storage: University NAS/HPC; automatic backups managed by IT.</li> <li>Collaboration: Nextcloud for files that require sharing/sync.</li> <li>Do not store research data on personal devices.</li> </ul>"},{"location":"manual/08_TOOLS_AND_PLATFORMS/#computing-analysis","title":"Computing &amp; Analysis","text":"<ul> <li>Python (Conda/Poetry), R (renv), Jupyter/Quarto for notebooks/reports.</li> <li>Workflow management: Snakemake or Nextflow for pipelines.</li> <li>Geospatial: GDAL, QGIS; remote sensing libraries (rasterio, xarray).</li> </ul>"},{"location":"manual/08_TOOLS_AND_PLATFORMS/#validation-metadata","title":"Validation &amp; Metadata","text":"<ul> <li>Frictionless Data (frictionless-py) for schema &amp; data package.</li> <li>Pandera (Python) / pointblank (R) for data validation.</li> <li>Metadata: Markdown READMEs, Dublin Core elements, CITATION.cff.</li> </ul>"},{"location":"manual/08_TOOLS_AND_PLATFORMS/#version-control-cicd","title":"Version Control &amp; CI/CD","text":"<ul> <li>GitLab with protected branches and MR reviews.</li> <li>Enable Git LFS; add CI pipelines for tests and checks.</li> </ul>"},{"location":"manual/08_TOOLS_AND_PLATFORMS/#publishing","title":"Publishing","text":"<ul> <li>Zenodo integration for DOIs; domain repositories (PANGAEA, GBIF, Dryad).</li> </ul>"},{"location":"manual/09_PUBLISHING_AND_REUSE/","title":"09 \u2014 Publishing &amp; Reuse","text":""},{"location":"manual/09_PUBLISHING_AND_REUSE/#repository-selection","title":"Repository Selection","text":"<ul> <li>General-purpose: Zenodo (code+data, DOI).</li> <li>Environmental/Earth: PANGAEA.</li> <li>Biodiversity/occurrence: GBIF (via IPT/publisher).</li> <li>Life sciences: Dryad.</li> </ul>"},{"location":"manual/09_PUBLISHING_AND_REUSE/#licensing","title":"Licensing","text":"<ul> <li>Default: CC-BY 4.0 for data unless restricted; MIT/BSD for code.</li> <li>Respect third-party licenses; document any limitations.</li> </ul>"},{"location":"manual/09_PUBLISHING_AND_REUSE/#submission-package","title":"Submission Package","text":"<ul> <li>Cleaned data with versioned filenames.</li> <li><code>README.md</code> and <code>data_dictionary.csv</code>.</li> <li>Code snapshot and environment files (or container recipe).</li> <li>Citation text and contributors.</li> </ul>"},{"location":"manual/09_PUBLISHING_AND_REUSE/#doi-citation","title":"DOI &amp; Citation","text":"<ul> <li>Mint DOI on release; include in publications.</li> <li>Example citation format:   \"Author(s) (Year). Title. Repository. DOI\"</li> </ul>"},{"location":"manual/09_PUBLISHING_AND_REUSE/#embargo-access","title":"Embargo &amp; Access","text":"<ul> <li>Use embargo periods when needed; state release date.</li> <li>For sensitive data, publish metadata with controlled access to data.</li> </ul>"},{"location":"manual/10_CHECKLISTS_AND_TEMPLATES/","title":"10 \u2014 Checklists &amp; Templates","text":"<p>Use these checklists during the project lifecycle: - <code>manual/templates/checklist_project_start.md</code> - <code>manual/templates/checklist_ongoing.md</code> - <code>manual/templates/checklist_closure.md</code> - <code>manual/templates/qa_checklist.md</code> - <code>manual/templates/software_practices_checklist.md</code></p> <p>Key templates: - Dataset README: <code>manual/templates/README_dataset.md</code> - Project README: <code>manual/templates/PROJECT_README.md</code> - Data Dictionary: <code>manual/templates/data_dictionary.csv</code> - DMP Outline: <code>manual/templates/DMP_outline.md</code> - CITATION: <code>manual/templates/CITATION.cff</code> - Pipeline skeleton: <code>manual/templates/Snakefile</code> + <code>manual/templates/environment.yml</code> - Frictionless Data Package: <code>manual/templates/datapackage.json</code></p>"},{"location":"manual/11_SOFTWARE_PRACTICES/","title":"11 \u2014 Software Practices (Sustainable Code)","text":"<p>Practical guidance for writing maintainable, reviewable, and reusable research code.</p>"},{"location":"manual/11_SOFTWARE_PRACTICES/#core-practices","title":"Core Practices","text":"<ul> <li>Version control: Git with feature branches, small PRs, and reviews.</li> <li>Documentation: README, inline docstrings, minimal examples.</li> <li>Testing: Unit tests for critical functions; smoke tests for pipelines.</li> <li>Environments: Pin dependencies (Conda/Poetry/renv); use lock files.</li> <li>Automation: Makefiles or task runners; CI for tests and linting.</li> <li>Packaging: Structure code as packages/modules; semantic versioning.</li> </ul>"},{"location":"manual/11_SOFTWARE_PRACTICES/#language-specific-tips","title":"Language-specific Tips","text":"<ul> <li>Python: <code>pyproject.toml</code>, <code>ruff</code>/<code>black</code> lint/format, <code>pytest</code>, <code>tox</code> (optional).</li> <li>R: <code>renv</code>, <code>testthat</code>, <code>lintr</code>, <code>targets</code> for pipelines.</li> </ul>"},{"location":"manual/11_SOFTWARE_PRACTICES/#reproducible-workflows","title":"Reproducible Workflows","text":"<ul> <li>Use Snakemake/Nextflow or R <code>targets</code> to codify steps and dependencies.</li> <li>Save intermediate artifacts deterministically; avoid manual steps.</li> <li>Capture parameters/config in YAML/TOML files.</li> </ul>"},{"location":"manual/11_SOFTWARE_PRACTICES/#collaboration","title":"Collaboration","text":"<ul> <li>Code reviews: focus on clarity, correctness, and performance where relevant.</li> <li>Issues and milestones: track tasks and releases.</li> <li>Contribution guidelines: define style, tests, and DCO/CLA if needed.</li> </ul>"},{"location":"manual/11_SOFTWARE_PRACTICES/#sustainability-archival","title":"Sustainability &amp; Archival","text":"<ul> <li>Release code with a tag and <code>CITATION.cff</code>; archive on Zenodo for DOI.</li> <li>Include a minimal dataset or synthetic data for examples/tests.</li> <li>Add maintenance status in README and an OWNER file.</li> </ul>"},{"location":"manual/11_SOFTWARE_PRACTICES/#checklist","title":"Checklist","text":"<p>See <code>manual/templates/software_practices_checklist.md</code>.</p>"}]}